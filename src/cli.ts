#!/usr/bin/env node

import { Command } from 'commander';
import * as path from 'path';
import * as fs from 'fs/promises';
import * as fsSync from 'fs';
import { execSync } from 'child_process';

// –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
import { logger, LogLevel } from './logger.js';
import { 
  getCommitHistory, 
  aggregateByDay, 
  getCurrentBranch, 
  checkoutCommit, 
  restoreBranch,
  findMigrationStart 
} from './git/index.js';
import { analyzeFolder } from './analysis/index.js';
import { 
  ProgressData, 
  DataPoint, 
  MetaInfo, 
  DailyCommit 
} from './data/schema.js';
import { 
  validateProgressData, 
  loadExistingData, 
  mergeData, 
  getLastTimestamp, 
  saveData 
} from './data/index.js';
import { commitIfChanged } from './git-ops/index.js';
import {
  getCachePath,
  loadCache,
  saveCache,
  validateCache,
  createCache,
  cacheToCommitInfo,
} from './cache/index.js';

interface ConfigFile {
  repo: string;
  old: string;
  new: string;
  output: string;
  force?: boolean;
  cache?: string;
  logLevel?: LogLevel;
  ignoreOld?: string[];
  ignoreNew?: string[];
}

interface CliOptions {
  repo?: string;
  old?: string;
  new?: string;
  output?: string;
  force: boolean;
  cache?: string;
  logLevel: LogLevel;
  ignoreOld?: string;
  ignoreNew?: string;
  config?: string;
}

function loadConfigFile(configPath: string): ConfigFile {
  const content = fsSync.readFileSync(configPath, 'utf-8');
  return JSON.parse(content) as ConfigFile;
}

async function main(): Promise<void> {
  // 1. –ü–∞—Ä—Å–∏–Ω–≥ CLI
  const program = new Command();
  program
    .option('--config <path>', 'Path to config JSON file')
    .option('--repo <path>', 'Path to source repository')
    .option('--old <path>', 'Old folder path (relative to repo)')
    .option('--new <path>', 'New folder path (relative to repo)')
    .option('--output <path>', 'Output JSON file path')
    .option('--force', 'Force full recalculation', false)
    .option('--cache <path>', 'Path to cache file')
    .option('--log-level <level>', 'Log level: debug|info|warn|error', 'info')
    .option('--ignore-old <folders>', 'Comma-separated subfolders to ignore in old path')
    .option('--ignore-new <folders>', 'Comma-separated subfolders to ignore in new path')
    .parse();

  const cliOpts = program.opts<CliOptions>();
  
  // Load config file if specified
  let config: ConfigFile | null = null;
  if (cliOpts.config) {
    config = loadConfigFile(path.resolve(cliOpts.config));
  }
  
  // Merge config with CLI options (CLI takes precedence)
  const repo = cliOpts.repo ?? config?.repo;
  const old = cliOpts.old ?? config?.old;
  const newPath = cliOpts.new ?? config?.new;
  const output = cliOpts.output ?? config?.output;
  
  if (!repo || !old || !newPath || !output) {
    console.error('Error: --repo, --old, --new, and --output are required (via CLI or config file)');
    process.exit(1);
  }
  
  const force = cliOpts.force || config?.force || false;
  const cache = cliOpts.cache ?? config?.cache;
  const logLevel = cliOpts.logLevel ?? config?.logLevel ?? 'info';
  const ignoreOldStr = cliOpts.ignoreOld ?? config?.ignoreOld?.join(',');
  const ignoreNewStr = cliOpts.ignoreNew ?? config?.ignoreNew?.join(',');
  
  // Set log level
  logger.setLevel(logLevel);
  
  // –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏
  const repoPath = path.resolve(repo);
  const outputPath = path.resolve(output);
  const oldPath = old;  // –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ repo
  const newFolderPath = newPath;  // –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ repo
  const cachePath = getCachePath(outputPath, cache);
  const ignoreOld = ignoreOldStr?.split(',').map(s => s.trim()).filter(Boolean);
  const ignoreNew = ignoreNewStr?.split(',').map(s => s.trim()).filter(Boolean);

  logger.info('INIT', 'Starting analysis', {
    repo: repoPath,
    oldPath,
    newPath: newFolderPath,
    output: outputPath,
    cache: cachePath,
    ignoreOld,
    ignoreNew,
    force,
  });

  // 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
  let existingData: ProgressData | null = null;
  if (!force) {
    existingData = await loadExistingData(outputPath);
    if (existingData) {
      logger.info('INIT', `Loaded existing data with ${existingData.data.length} points`);
    }
  }

  // 3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–æ—á–∫—É —Å—Ç–∞—Ä—Ç–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ (—Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
  let migrationStart;
  
  if (!force) {
    const cachedData = await loadCache(cachePath);
    if (cachedData && validateCache(cachedData, repoPath, oldPath, newFolderPath)) {
      migrationStart = cacheToCommitInfo(cachedData);
      logger.info('CACHE', `Using cached migration start: ${migrationStart.hash.substring(0, 7)}`);
    }
  }
  
  if (!migrationStart) {
    logger.info('GIT', 'Finding migration start point...');
    migrationStart = await findMigrationStart(repoPath, oldPath, newFolderPath);
    
    // Save to cache
    const cacheData = createCache(migrationStart, oldPath, newFolderPath);
    await saveCache(cachePath, cacheData);
  }
  
  logger.info('GIT', `Migration started at commit ${migrationStart.hash.substring(0, 7)}`);

  // 4. –ü–æ–ª—É—á–∏—Ç—å git log
  logger.info('GIT', 'Fetching commit history...');
  const allCommits = await getCommitHistory(repoPath);
  
  // –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–º–º–∏—Ç—ã –Ω–∞—á–∏–Ω–∞—è —Å —Ç–æ—á–∫–∏ —Å—Ç–∞—Ä—Ç–∞
  const relevantCommits = allCommits.filter(c => c.timestamp >= migrationStart.timestamp);
  logger.info('GIT', `Found ${relevantCommits.length} commits since migration start`);

  // 5. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
  const dailyCommits = aggregateByDay(relevantCommits);
  logger.info('AGGREGATE', `Aggregated to ${dailyCommits.length} daily data points`);

  // 6. –§–∏–ª—å—Ç—Ä—É–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
  const lastTimestamp = getLastTimestamp(existingData);
  const newDailyCommits = dailyCommits.filter(dc => {
    // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –≤ timestamp –Ω–∞—á–∞–ª–∞ –¥–Ω—è UTC
    const dayStart = new Date(dc.date + 'T00:00:00Z').getTime() / 1000;
    return dayStart > lastTimestamp;
  });
  
  if (newDailyCommits.length === 0) {
    logger.info('AGGREGATE', 'No new data points to process');
  } else {
    logger.info('AGGREGATE', `Processing ${newDailyCommits.length} new days...`);
  }

  // 7. –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤—ã—Ö –∫–æ–º–º–∏—Ç–æ–≤
  const newPoints: DataPoint[] = [];
  
  if (newDailyCommits.length > 0) {
    const originalBranch = await getCurrentBranch(repoPath);
    
    try {
      for (const dc of newDailyCommits) {
        logger.info('CHECKOUT', `Analyzing ${dc.date} (${dc.hash.substring(0, 7)})...`);
        
        await checkoutCommit(repoPath, dc.hash);
        
        const oldFullPath = path.join(repoPath, oldPath);
        const newFullPath = path.join(repoPath, newFolderPath);
        
        const oldStats = await analyzeFolder(oldFullPath, ignoreOld);
        const newStats = await analyzeFolder(newFullPath, ignoreNew);
        
        // Timestamp = –Ω–∞—á–∞–ª–æ –¥–Ω—è UTC
        const dayTimestamp = new Date(dc.date + 'T00:00:00Z').getTime() / 1000;
        
        const newPoint: DataPoint = {
          time: dayTimestamp,
          oldSizeKB: oldStats.sizeKB,
          newSizeKB: newStats.sizeKB,
          oldFiles: oldStats.files,
          newFiles: newStats.files,
        };
        
        newPoints.push(newPoint);
        
        logger.info('COUNT', `old: ${oldStats.sizeKB} KB, ${oldStats.files} files`);
        logger.info('COUNT', `new: ${newStats.sizeKB} KB, ${newStats.files} files`);
        
        // üîÑ –ü–†–û–ì–†–ï–°–°–ò–í–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è
        try {
          // –ü–æ–ª—É—á–∞–µ–º remote URL –¥–ª—è meta
          let sourceRepoUrl: string;
          try {
            sourceRepoUrl = execSync('git remote get-url origin', { 
              cwd: repoPath, 
              encoding: 'utf-8' 
            }).trim();
          } catch {
            sourceRepoUrl = repoPath;
          }

          const progressMeta: MetaInfo = {
            sourceRepo: sourceRepoUrl,
            oldPath: oldPath,
            newPath: newFolderPath,
            generatedAt: new Date().toISOString(),
            version: 2,
            ignoredSubfolders: (ignoreOld || ignoreNew) ? {
              old: ignoreOld,
              new: ignoreNew,
            } : undefined,
          };

          // –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –Ω–æ–≤—ã–º–∏ —Ç–æ—á–∫–∞–º–∏
          const progressData = mergeData(existingData, newPoints, progressMeta, false);
          
          // –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
          await fs.writeFile(outputPath, JSON.stringify(progressData, null, 2), 'utf-8');
          logger.info('SAVE', `Saved progress: ${newPoints.length} days processed`);
          
          // üßπ –û–ß–ò–°–¢–ö–ê –ü–ê–ú–Ø–¢–ò: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
          if (global.gc) {
            global.gc();
            logger.debug('GC', 'Manual garbage collection triggered');
          }
        } catch (saveErr) {
          logger.warn('SAVE', `Failed to save progress: ${saveErr instanceof Error ? saveErr.message : String(saveErr)}`);
          // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–∞–∂–µ –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
        }
      }
    } finally {
      // 8. –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω—É—é –≤–µ—Ç–∫—É
      await restoreBranch(repoPath, originalBranch);
      logger.info('CHECKOUT', `Restored to ${originalBranch}`);
    }
  }

  // 9. –ü–æ–ª—É—á–∏—Ç—å remote URL –¥–ª—è meta
  let sourceRepoUrl: string;
  try {
    sourceRepoUrl = execSync('git remote get-url origin', { 
      cwd: repoPath, 
      encoding: 'utf-8' 
    }).trim();
  } catch {
    sourceRepoUrl = repoPath;  // fallback –Ω–∞ –ø—É—Ç—å
  }

  const meta: MetaInfo = {
    sourceRepo: sourceRepoUrl,
    oldPath: oldPath,
    newPath: newFolderPath,
    generatedAt: new Date().toISOString(),
    version: 2,
    ignoredSubfolders: (ignoreOld || ignoreNew) ? {
      old: ignoreOld,
      new: ignoreNew,
    } : undefined,
  };

  // –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
  const finalData = mergeData(existingData, newPoints, meta, force);

  // 10. –í–∞–ª–∏–¥–∞—Ü–∏—è
  logger.info('VALIDATE', 'Validating data...');
  validateProgressData(finalData);
  logger.info('VALIDATE', 'Validation passed');

  // 11. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
  await saveData(outputPath, finalData);
  logger.info('SAVE', `Saved ${finalData.data.length} data points to ${outputPath}`);

  // 12. –ö–æ–º–º–∏—Ç –∏ –ø—É—à
  const committed = await commitIfChanged(
    outputPath, 
    'Update migration progress data'
  );
  
  if (committed) {
    logger.info('GIT-OPS', 'Changes committed and pushed');
  } else {
    logger.info('GIT-OPS', 'No changes to commit');
  }

  logger.info('DONE', 'Completed successfully');
}

main().catch((err) => {
  logger.error('FATAL', err.message);
  process.exit(1);
});
